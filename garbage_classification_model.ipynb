{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 垃圾分类模型训练\n",
        "\n",
        "本notebook用于训练垃圾分类模型并转换为TensorFlow Lite格式，以便在Android应用中使用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置参数\n",
        "IMAGE_SIZE = 224  # 图像大小\n",
        "BATCH_SIZE = 32   # 批量大小\n",
        "EPOCHS = 20       # 训练轮数\n",
        "NUM_CLASSES = 6   # 分类数量：cardboard, glass, metal, paper, plastic, trash\n",
        "\n",
        "# 数据集路径\n",
        "DATASET_PATH = \"Garbage classification/Garbage classification\"\n",
        "\n",
        "# 确认数据集路径存在\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    raise Exception(f\"数据集路径不存在: {DATASET_PATH}\")\n",
        "\n",
        "# 列出所有分类\n",
        "categories = os.listdir(DATASET_PATH)\n",
        "print(f\"分类类别: {categories}\")\n",
        "print(f\"分类数量: {len(categories)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据增强和预处理\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,  # 20%数据用于验证\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 仅进行缩放的验证数据生成器\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# 训练数据生成器\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 验证数据生成器\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 获取类别索引映射\n",
        "class_indices = train_generator.class_indices\n",
        "print(\"类别索引映射:\")\n",
        "print(class_indices)\n",
        "\n",
        "# 反转映射，用于之后的标签解码\n",
        "class_names = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "# 保存类别名称，用于Android应用\n",
        "with open('class_names.txt', 'w') as f:\n",
        "    for i in range(len(class_names)):\n",
        "        f.write(f\"{class_names[i]}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 构建模型\n",
        "model = Sequential([\n",
        "    # 第一个卷积块\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    \n",
        "    # 第二个卷积块\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    \n",
        "    # 第三个卷积块\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    \n",
        "    # 第四个卷积块\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    \n",
        "    # 展平层\n",
        "    Flatten(),\n",
        "    \n",
        "    # 全连接层\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),  # 防止过拟合\n",
        "    Dense(NUM_CLASSES, activation='softmax')  # 输出层，6个分类\n",
        "])\n",
        "\n",
        "# 编译模型\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 打印模型摘要\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置回调函数\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'garbage_classification_model_best.h5',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 训练模型\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 绘制训练过程\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='训练准确率')\n",
        "plt.plot(val_acc, label='验证准确率')\n",
        "plt.legend()\n",
        "plt.title('准确率')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='训练损失')\n",
        "plt.plot(val_loss, label='验证损失')\n",
        "plt.legend()\n",
        "plt.title('损失')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 评估模型\n",
        "evaluation = model.evaluate(validation_generator)\n",
        "print(f\"验证损失: {evaluation[0]:.4f}\")\n",
        "print(f\"验证准确率: {evaluation[1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存模型\n",
        "model.save('garbage_classification_model.h5')\n",
        "print(\"模型已保存为 garbage_classification_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 转换为TensorFlow Lite格式\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# 保存TFLite模型\n",
        "with open('garbage_classification_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "    \n",
        "print(\"TensorFlow Lite模型已保存为 garbage_classification_model.tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 量化模型（减小模型大小，适合移动设备）\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# 保存量化后的TFLite模型\n",
        "with open('garbage_classification_model_quantized.tflite', 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n",
        "    \n",
        "print(\"量化后的TensorFlow Lite模型已保存为 garbage_classification_model_quantized.tflite\")\n",
        "print(f\"原始模型大小: {len(tflite_model) / 1024:.2f} KB\")\n",
        "print(f\"量化后模型大小: {len(tflite_quant_model) / 1024:.2f} KB\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
